{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Edt5toj9MqDq"
      },
      "source": [
        "# New York City Taxi Fare Prediction\n",
        "\n",
        "This project is a part of the course offered by Jovian: Machine Learning with Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sYlKgXPMqDt"
      },
      "source": [
        "We will be training a Machine Learning model to predict which shoppers will become repeat buyers given information like transaction history of customers, incentive offered to each customer, and their response to the offer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CX9DK6QOMqDu"
      },
      "source": [
        "Dataset link: https://www.kaggle.com/competitions/acquire-valued-shoppers-challenge/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofXnf8Y9YQnl"
      },
      "source": [
        "# Project Outline:\n",
        "- Downloading the Dataset\n",
        "- Exploring the Dataset\n",
        "- Preparing the Dataset for training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjU0c7nuMqDu"
      },
      "source": [
        "# 1. Downloading the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xb9brdMrMqDu"
      },
      "source": [
        "(1.1)  Installing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52vbr7H0MqDv",
        "outputId": "c2971048-8b8b-4a93-f787-098a87f62b86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/68.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m61.4/68.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.6/68.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for uuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install jovian opendatasets pandas numpy scikit-learn xgboost --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bLReEUqMqDw"
      },
      "outputs": [],
      "source": [
        "import jovian"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJSBKuscMqDw",
        "outputId": "e87937af-e08f-4ffc-f777-d3cf2f3a2038"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] jovian.commit() is no longer required on Google Colab. If you ran this notebook from Jovian, \n",
            "then just save this file in Colab using Ctrl+S/Cmd+S and it will be updated on Jovian. \n",
            "Also, you can also delete this cell, it's no longer necessary.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "jovian.commit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BDjhUm_MqDw"
      },
      "source": [
        "(1.2) Downloading data from kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjS3dMW3MqDx"
      },
      "outputs": [],
      "source": [
        "import opendatasets as od"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4hG8yt4MqDx"
      },
      "outputs": [],
      "source": [
        "dataset_url = 'https://www.kaggle.com/competitions/new-york-city-taxi-fare-prediction/data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZJYcQTeMqDx",
        "outputId": "489c28c2-7485-445f-d29c-c0fb67eb8b18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username:"
          ]
        }
      ],
      "source": [
        "od.download(dataset_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b05GFrADWFnw"
      },
      "outputs": [],
      "source": [
        "data_dir = 'new-york-city-taxi-fare-prediction'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFsK8v90WUSe"
      },
      "source": [
        "(1.3) Viewing dataset files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eu3kvsRjWOtZ"
      },
      "outputs": [],
      "source": [
        "#getting the size of files\n",
        "!ls -lh {data_dir}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--_2szNggqHY"
      },
      "outputs": [],
      "source": [
        "!wc -l {data_dir}/train.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_TwE-AUg6iH"
      },
      "outputs": [],
      "source": [
        "!wc -l {data_dir}/test.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qogZXiI7hGKm"
      },
      "outputs": [],
      "source": [
        "!head {data_dir}/train.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqusc9g3hRHV"
      },
      "outputs": [],
      "source": [
        "!head {data_dir}/test.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lRWBOLQ18n3"
      },
      "source": [
        "What does the sample submission file look like? Let's take a look:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ujkrjv_ieGl"
      },
      "outputs": [],
      "source": [
        "!head {data_dir}/sample_submission.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5kireiG_jzX"
      },
      "source": [
        "OBSERVATIONS:\n",
        "- This is a supervised learning regression problem\n",
        "- The training data is 5.4 GB in size\n",
        "- The test data is 960 KB in size\n",
        "- The training set has 8 columns:\n",
        "   - key\n",
        "   - fare_amount (target column)\n",
        "   - pickup_datetime\n",
        "   - pickup_longitude\n",
        "   - pickup_latitude\n",
        "   - dropoff_longitude\n",
        "   - dropoff_latitude\n",
        "   - passenger_count\n",
        "- The test set contains the same columns except the fare_amount column\n",
        "- The submission file should contain the key and fare_amount"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwX13gkaByvI"
      },
      "source": [
        "(1.4) Loading Training Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4gaZtsUCMfm"
      },
      "outputs": [],
      "source": [
        "selected_cols = 'key,pickup_datetime,fare_amount,pickup_longitude,pickup_latitude,dropoff_longitude,dropoff_latitude,passenger_count'.split(',')\n",
        "selected_cols\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7Dkxpq94tRo"
      },
      "outputs": [],
      "source": [
        "dtypes = {\n",
        " 'fare_amount': 'float32',\n",
        " 'pickup_longitude': 'float32',\n",
        " 'pickup_latitude': 'float32',\n",
        " 'dropoff_longitude': 'float32',\n",
        " 'dropoff_latitude': 'float32',\n",
        " 'passenger_count': 'uint8'\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfKGBgg_owMx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3K6qR1yKQVY"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "def skip_row(idx):\n",
        "  if idx == 0:\n",
        "    return False\n",
        "  return random.random() > 0.01\n",
        "random.seed(42)\n",
        "train_df = pd.read_csv(data_dir+ '/train.csv' , dtype = dtypes, usecols = selected_cols, skiprows = skip_row, parse_dates = ['pickup_datetime'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgL-BCHrUaNO"
      },
      "outputs": [],
      "source": [
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBMGfk43MqDx"
      },
      "outputs": [],
      "source": [
        "jovian.commit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fr7MEqcAUNFw"
      },
      "source": [
        "(1.5) Loading Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvrJOyeSMqDx"
      },
      "outputs": [],
      "source": [
        "test_df = pd.read_csv(data_dir+ '/test.csv', dtype = dtypes, parse_dates = ['pickup_datetime'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqtpVVF1Ur0F"
      },
      "outputs": [],
      "source": [
        "test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imQse15ZX0Ta"
      },
      "outputs": [],
      "source": [
        "jovian.commit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yj2Uka7sYFnq"
      },
      "source": [
        "# 2. Exploring the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPnoThZWY3iK"
      },
      "source": [
        "(2.1) Training Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trWJ-JG5YOIG"
      },
      "outputs": [],
      "source": [
        "train_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAvbkxh1Y7aI"
      },
      "outputs": [],
      "source": [
        "train_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-RnPtqdkdNVf"
      },
      "outputs": [],
      "source": [
        "train_df['pickup_datetime'].min(), train_df['pickup_datetime'].max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6Kq8buWa-1i"
      },
      "source": [
        "OBSERVATIONS ABOUT TRAINING DATA:\n",
        "- No missing data (in sample)\n",
        "- passenger_count ranges from 0 to 208\n",
        "- fare_amount ranges from -52 to 499\n",
        "- Errors in longitude and latitude values\n",
        "- The training set contains details of rides from 1st Jan 2009 to 30th June 2015\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waOCMKbMdMwy"
      },
      "outputs": [],
      "source": [
        "jovian.commit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4DXrhZLj-7h"
      },
      "source": [
        "(2.2) Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RxiVGAGkj92o"
      },
      "outputs": [],
      "source": [
        "test_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKvuA7Ncbyf6"
      },
      "outputs": [],
      "source": [
        "test_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWZuS-dTwNV7"
      },
      "outputs": [],
      "source": [
        "test_df['pickup_datetime'].min(), test_df['pickup_datetime'].max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orVvy-24lOoc"
      },
      "source": [
        "OBSERVATIONS ABOUT TEST DATA:\n",
        "- Around 10k rows of data\n",
        "- No missing values\n",
        "- Pickup dates are in the same range as the training data\n",
        "- passenger_count is between 1 and 6, so we can limit training data to this range"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "At1L4xKTbuIz"
      },
      "source": [
        "(2.3) Exploratory Data Analysis and Visualization\n",
        "\n",
        "Let's perform some exploratory analysis to gain a deeper understanding of our data\n",
        "\n",
        "Let's begin by importing the libraries required for data visualisation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QWZ7jw1lntU"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "sns.set_style('darkgrid')\n",
        "matplotlib.rcParams['font.size'] = 14\n",
        "matplotlib.rcParams['figure.figsize'] = (10, 6)\n",
        "matplotlib.rcParams['figure.facecolor'] = '#00000000'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFu61iQkmYfc"
      },
      "outputs": [],
      "source": [
        "train_df.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8P2mToallpDU"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(train_df.corr())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXJ0sZJEkxQ3"
      },
      "outputs": [],
      "source": [
        "train_df.corr()['fare_amount'].sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfNSusk6oLvh"
      },
      "source": [
        "We can make out that the fare_amount column has the highest positive correlation with the passenger_count column, which is quite intuitive. More passengers can indicate the need of bigger taxis, which in turn will have higher fares.\n",
        "\n",
        "However it wouldn't be fare to make any conclusions based of this data, as we still need to do some feature engineering to calculate the distance between the pickup and dropoff locations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgTkdERft3xZ"
      },
      "source": [
        "Let's also take a look at how the chain colun impacts the number of repeat trips"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvZdCJYfnvQA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "plt.figure(figsize=(17, 8))\n",
        "plt.title(\"Distribution of fare_amount\")\n",
        "plt.hist(train_df['fare_amount'], color = 'orange');\n",
        "plt.xlabel(\"Fare amount\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3wqVhveDuhp"
      },
      "outputs": [],
      "source": [
        "\n",
        "plt.figure(figsize=(17, 8))\n",
        "plt.title(\"Ratings of Sephoras' products\")\n",
        "plt.hist(train_df['passenger_count'], bins = np.arange(1,6),color = 'orange');\n",
        "plt.xlabel(\"Fare amount\")\n",
        "plt.ylabel(\"No. of products\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRV9BWAMt_YU"
      },
      "source": [
        "We can see that even though chain column has a lower correlation with the repeattrips column, it is quite evident that customers prefer going back in certain chains more than the rest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSu6cKt1CaAm"
      },
      "source": [
        "#3. Preparing the Dataset for training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcCjc3HqCrpB"
      },
      "source": [
        "(3.1) Splitting training and validation set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5iLkkfrFxrP"
      },
      "source": [
        "We will set aside 20% of our training data as validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eViE-b9B0Xw"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zw-Uqzq3FU85"
      },
      "outputs": [],
      "source": [
        "train_new_df, val_df = train_test_split(train_df, test_size = 0.2, random_state = 42)\n",
        "len(train_new_df), len(val_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1uWRPLfG1tT"
      },
      "source": [
        "(3.2) Extract Inputs and Outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ioOxPLbrGreG"
      },
      "outputs": [],
      "source": [
        "train_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QQ8iNqEIfar"
      },
      "outputs": [],
      "source": [
        "input_cols = ['pickup_longitude',\n",
        "       'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n",
        "       'passenger_count']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jiLD3ihkIxMJ"
      },
      "outputs": [],
      "source": [
        "target_col = 'fare_amount'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abZPE9wiJ0i6"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zz5NX52XJy0g"
      },
      "outputs": [],
      "source": [
        "train_inputs = train_df[input_cols]\n",
        "train_targets = train_df[target_col]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4W1_U3NKAlR"
      },
      "outputs": [],
      "source": [
        "train_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZATnmDYZKL-5"
      },
      "outputs": [],
      "source": [
        "train_targets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gNw2sjnMm5Q"
      },
      "source": [
        "Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuwzEL8JK35N"
      },
      "outputs": [],
      "source": [
        "val_inputs = val_df[input_cols]\n",
        "val_targets = val_df[target_col]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_0rAfwLMzGV"
      },
      "outputs": [],
      "source": [
        "val_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PD5xW1YmM369"
      },
      "outputs": [],
      "source": [
        "val_targets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyO5W3ZANBDI"
      },
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPk8VdPyM7XO"
      },
      "outputs": [],
      "source": [
        "test_inputs = test_df[input_cols]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbwveKcFM7it"
      },
      "outputs": [],
      "source": [
        "test_inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbgHOK1pNYL5"
      },
      "source": [
        "# 4. Train Hardcoded and Baseline Models\n",
        "\n",
        "(4.1) Let's create a simple model that predicts the average"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nl1r1U_FNOp3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "class MeanRegressor:\n",
        "  def fit(self, inputs, targets):\n",
        "    self.mean = round(targets.mean())\n",
        "\n",
        "  def predict(self, inputs):\n",
        "    return np.full(inputs.shape[0],int(self.mean))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUqvhe9wl_gA"
      },
      "outputs": [],
      "source": [
        "mean_model = MeanRegressor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gkm7GthmINh"
      },
      "outputs": [],
      "source": [
        "mean_model.fit(train_inputs, train_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2DazG6kyK7o"
      },
      "outputs": [],
      "source": [
        "mean_model.mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESmjubnNyoYt"
      },
      "outputs": [],
      "source": [
        "train_preds = mean_model.predict(train_inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pG0_7bHMyyZj"
      },
      "outputs": [],
      "source": [
        "train_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvW7e9xWy4lh"
      },
      "outputs": [],
      "source": [
        "val_preds = mean_model.predict(val_inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDQt918Wy98p"
      },
      "outputs": [],
      "source": [
        "val_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9ReV9BMzS-w"
      },
      "outputs": [],
      "source": [
        "val_targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGx4KTSizXpe"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmdCwSjUzrZR"
      },
      "outputs": [],
      "source": [
        "def rmse(targets,preds):\n",
        "  return mean_squared_error(targets,preds,squared = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dOpTXvt1SZJ"
      },
      "outputs": [],
      "source": [
        "train_rmse = rmse(train_targets, train_preds)\n",
        "train_rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYc5UYvw2KyG"
      },
      "outputs": [],
      "source": [
        "val_rmse = rmse(val_targets, val_preds)\n",
        "val_rmse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wE8cWwaa2fa5"
      },
      "source": [
        "(4.2) Train and evaluate baseline model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpKLP_tJ2jMy"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6zjhmW22uSO"
      },
      "outputs": [],
      "source": [
        "linear_model = LinearRegression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hI_QNMV3ElU"
      },
      "outputs": [],
      "source": [
        "linear_model.fit(train_inputs, train_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUj89kx-3MGf"
      },
      "outputs": [],
      "source": [
        "train_preds = linear_model.predict(train_inputs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIvN7qMs3Ycj"
      },
      "outputs": [],
      "source": [
        "train_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48Ivp-qu3Z9A"
      },
      "outputs": [],
      "source": [
        "train_targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBkb85ljVoZD"
      },
      "outputs": [],
      "source": [
        "rmse(train_targets, train_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecCOj71NVoi0"
      },
      "outputs": [],
      "source": [
        "val_preds = linear_model.predict(val_inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOEmtH41Wa-p"
      },
      "outputs": [],
      "source": [
        "rmse(val_targets, val_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfWISzuqTjwq"
      },
      "source": [
        "## 5. Make predictions and submit to kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SfX9MumTi_0"
      },
      "outputs": [],
      "source": [
        "test_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtZ7kTT8UIKs"
      },
      "outputs": [],
      "source": [
        "test_preds = linear_model.predict(test_inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKTryFBU-oTi"
      },
      "outputs": [],
      "source": [
        "test_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hczXr2pxaRY5"
      },
      "outputs": [],
      "source": [
        "submission_df = pd.read_csv('/content/new-york-city-taxi-fare-prediction/sample_submission.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDQTZdCzAgmW"
      },
      "outputs": [],
      "source": [
        "submission_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uM0QVbjEAyI6"
      },
      "outputs": [],
      "source": [
        "submission_df['fare_amount'] = test_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhYy6i6TGaYc"
      },
      "outputs": [],
      "source": [
        "submission_df.to_csv('submission.csv', index = None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKG1QDmZBCJD"
      },
      "outputs": [],
      "source": [
        "def submit(fname, model, test_inputs):\n",
        "  preds = model.predict(test_inputs)\n",
        "  submission_df = pd.read_csv('/content/new-york-city-taxi-fare-prediction/sample_submission.csv')\n",
        "  submission_df['fare_amount'] = preds\n",
        "  submission_df.to_csv(fname, index = None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgDuJAOfHXDC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SD77BKr0MQur"
      },
      "source": [
        "# 6. Feature Engineering\n",
        "\n",
        "-- extracting parts of date (day, month, year)\n",
        "\n",
        "-- removing outliers and invalid data\n",
        "\n",
        "-- adding distance between pickup and drop\n",
        "\n",
        "-- adding distance from Landmarks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZZXSYhPR3vK"
      },
      "source": [
        "(6.1) Extracting parts of Date\n",
        "\n",
        "Let's extract the year, month, day, weekday and hour from our datetime column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_WXCXteMUy6"
      },
      "outputs": [],
      "source": [
        "def extract_date(df,col):\n",
        "  df['Year'] = df[col].dt.year\n",
        "  df['Month'] = df[col].dt.month\n",
        "  df['Day'] = df[col].dt.day\n",
        "  df['WeekDay'] = df[col].dt.weekday\n",
        "  df['Hour'] = df[col].dt.hour"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "px7jU8rYUwIm"
      },
      "outputs": [],
      "source": [
        "extract_date(train_df, 'pickup_datetime')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJL0zVIhU6N2"
      },
      "outputs": [],
      "source": [
        "extract_date(val_df, 'pickup_datetime')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIgUy06MVVCA"
      },
      "outputs": [],
      "source": [
        "extract_date(test_df, 'pickup_datetime')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1Bvnd_NWC5F"
      },
      "outputs": [],
      "source": [
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hitokdvbWPYp"
      },
      "outputs": [],
      "source": [
        "val_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVlR45vmWSNf"
      },
      "outputs": [],
      "source": [
        "test_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQN5iYcSyZGP"
      },
      "source": [
        "(6.2) Adding distance between pickup and drop\n",
        "\n",
        "We will be using the Haversine formula\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEbCLhpKWVbX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def haversine_form(lon1, lat1, lon2, lat2):\n",
        "  lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
        "  dlon = lon2 - lon1\n",
        "  dlat = lat2 - lat1\n",
        "  a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0) ** 2\n",
        "  c = np.arcsin(np.sqrt(a))\n",
        "  km = 6367 * c\n",
        "  return km\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-bhWXZQ4hfr"
      },
      "outputs": [],
      "source": [
        "def trip_distance(df):\n",
        "  df['tripdistance'] = haversine_form(df['pickup_longitude'],df['pickup_latitude'],df['dropoff_longitude'] ,df['dropoff_latitude'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0i0Mru_kWYX"
      },
      "outputs": [],
      "source": [
        "trip_distance(train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2Wsr26Akbw7"
      },
      "outputs": [],
      "source": [
        "trip_distance(val_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZoHjrqns7JCQ"
      },
      "outputs": [],
      "source": [
        "trip_distance(test_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGbt818T7Cy_"
      },
      "source": [
        "(6.3) Adding distance from Landmarks\n",
        "\n",
        "Let's add the distance between the drop-off locations and popular destinations in New York to see if the promixity to popular landmarks has any effect on the taxi fare prediction\n",
        "\n",
        "Some popular landmarks in New York:\n",
        "- JFK Airport\n",
        "- LGA Airport\n",
        "- EWR Airport\n",
        "- Times Square\n",
        "- Met Museum\n",
        "- World Trade Centre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WI-oygq_6D7m"
      },
      "outputs": [],
      "source": [
        "jfk_lonlat = -73.7781, 40.6413\n",
        "lga_lonlat = -73.8740, 40.7769\n",
        "ewr_lonlat = -74.1745, 40.6895\n",
        "met_lonlat = -73.9632, 40.7794\n",
        "wtc_lonlat = -74.0099, 40.7126\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrOq7h2iChIk"
      },
      "outputs": [],
      "source": [
        "def add_landmark_distance(df, landmark, landmarklonlat):\n",
        "  lon,lat = landmarklonlat\n",
        "  df[landmark + 'dropoff_distance'] = haversine_form(lon,lat,df['dropoff_longitude'],df['dropoff_latitude'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aP1ATEsWDm_W"
      },
      "outputs": [],
      "source": [
        "landmarks = {'jfk': jfk_lonlat, 'lga': lga_lonlat, 'ewr': ewr_lonlat, 'met': met_lonlat, 'wtc': wtc_lonlat}\n",
        "def add_landmarks(df):\n",
        "  for i in landmarks:\n",
        "    add_landmark_distance(df, i, landmarks[i])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqvoMiDLFNQz"
      },
      "outputs": [],
      "source": [
        "add_landmarks(train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3-zYl3RFQGl"
      },
      "outputs": [],
      "source": [
        "add_landmarks(val_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSnUYYCbFTTg"
      },
      "outputs": [],
      "source": [
        "add_landmarks(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odFFQnGuyXAT"
      },
      "outputs": [],
      "source": [
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bf1nbGksyZou"
      },
      "outputs": [],
      "source": [
        "val_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MutEas0Hyypb"
      },
      "outputs": [],
      "source": [
        "test_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2woHXtg7w1sD"
      },
      "source": [
        "(6.4) Removing outliers and invalid data\n",
        "\n",
        "We noticed invalid data in the following columns when we did data analysis:\n",
        "\n",
        "- Pickup latitude and longitude\n",
        "- Drop latitude and longitude\n",
        "- Passenger count\n",
        "- Fare amount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0KC4UP03rVT"
      },
      "outputs": [],
      "source": [
        "test_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KxR8r3G23Tz"
      },
      "source": [
        "Modified ranges for the above columns:\n",
        "- Fare amount: $1-$500\n",
        "- longitudes: -75 - -72\n",
        "- latitudes: 40 - 42\n",
        "- passenger count: 1 to 6\n",
        "\n",
        "because the test set is limited to these ranges\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSbd4LTw2xbB"
      },
      "outputs": [],
      "source": [
        "def remove_outliers(df):\n",
        "  return df[(df['fare_amount']>=1.0) &\n",
        "            (df['fare_amount']<=500.0 )&\n",
        "            (df['pickup_longitude']>=-75) &\n",
        "            (df['pickup_longitude']<=-72 ) &\n",
        "            (df['dropoff_longitude']>=-75) &\n",
        "            (df['dropoff_longitude']<=-72) &\n",
        "            (df['pickup_latitude']>=40) &\n",
        "            (df['pickup_latitude']<=42 )&\n",
        "            (df['dropoff_latitude']>=40 )&\n",
        "            (df['dropoff_latitude']<=42) &\n",
        "            (df['passenger_count']>=1.0) &\n",
        "            (df['passenger_count']<=6.0 )\n",
        "  ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4I4TYWhdX-F"
      },
      "outputs": [],
      "source": [
        "train_df = remove_outliers(train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TcNT6f8iu8N"
      },
      "outputs": [],
      "source": [
        "val_df = remove_outliers(val_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZLSJnxzjGdc"
      },
      "source": [
        "#7. Train and evaluate different models\n",
        "\n",
        "We will be training each of the following models:\n",
        "- Ridge Regression\n",
        "- Random Forests\n",
        "- Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iLr_RrCi2Kc"
      },
      "outputs": [],
      "source": [
        "train_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NT1SVt1Cj4ii"
      },
      "outputs": [],
      "source": [
        "input_cols = ['pickup_longitude',\n",
        "       'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n",
        "       'passenger_count', 'Year', 'Month', 'Day', 'WeekDay', 'Hour',\n",
        "       'tripdistance', 'jfkdropoff_distance', 'lgadropoff_distance',\n",
        "       'ewrdropoff_distance', 'metdropoff_distance', 'wtcdropoff_distance']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97XQ3wVskYlT"
      },
      "outputs": [],
      "source": [
        "target_col = 'fare_amount'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1CUXemzlgKS"
      },
      "outputs": [],
      "source": [
        "train_inputs = train_df[input_cols]\n",
        "train_targets = train_df[target_col]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wiYjLM3mSFY"
      },
      "outputs": [],
      "source": [
        "val_inputs = val_df[input_cols]\n",
        "val_targets = val_df[target_col]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPbQVpkgmoeH"
      },
      "outputs": [],
      "source": [
        "test_inputs = test_df[input_cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFNY1g2xmbQv"
      },
      "outputs": [],
      "source": [
        "def evaluate(model):\n",
        "  train_preds = model.predict(train_inputs)\n",
        "  train_rmse = rmse(train_targets, train_preds)\n",
        "  val_preds = model.predict(val_inputs)\n",
        "  val_rmse = rmse(val_targets, val_preds)\n",
        "  return train_rmse, val_rmse, train_preds, val_preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K92zV4ISpXTe"
      },
      "source": [
        "Ridge Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgzDH6_yof5K"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Ridge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_tejJJup07X"
      },
      "outputs": [],
      "source": [
        "model1 = Ridge(random_state = 42, alpha = 0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwqBZCaXp_Q1"
      },
      "outputs": [],
      "source": [
        "model1.fit(train_inputs, train_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuRW3mO-qIoe"
      },
      "outputs": [],
      "source": [
        "evaluate(model1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaHEwKvCsAxZ"
      },
      "outputs": [],
      "source": [
        "submit('ridge_submission.csv', model1, test_inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iw7RddL7uRMJ"
      },
      "source": [
        "Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHv6ae1kt0l6"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2z0DtjZvAH1"
      },
      "outputs": [],
      "source": [
        "model2 = RandomForestRegressor(random_state = 42, n_jobs = -1, max_depth = 10 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdQciTgwwjhL"
      },
      "outputs": [],
      "source": [
        "model2.fit(train_inputs, train_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KE85zv1SwzPw"
      },
      "outputs": [],
      "source": [
        "evaluate(model2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fr0hLMePywPL"
      },
      "outputs": [],
      "source": [
        "submit('randomforest_submission.csv', model2, test_inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l14ifFo4zwsX"
      },
      "source": [
        "Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3V1S0y0zjT2"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "icPumQHb0Gez"
      },
      "outputs": [],
      "source": [
        "model3 = XGBRegressor(max_depth = 5,objective = 'reg:squarederror', n_estimators = 200, random_state = 42, n_jobs = -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICMYQ5Hd07EV"
      },
      "outputs": [],
      "source": [
        "model3.fit(train_inputs, train_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Urn-YANi0_gh"
      },
      "outputs": [],
      "source": [
        "evaluate(model3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Asd3ADbs1Frd"
      },
      "outputs": [],
      "source": [
        "submit('xgb_submission.csv', model3, test_inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TH7eK5x24zVC"
      },
      "source": [
        "# 8. Tune Hyperparameters for the XGBoost Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uU_kPt5h2qHT"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def test_params(ModelClass, **params):\n",
        "    model = ModelClass(**params).fit(train_inputs,train_targets)\n",
        "    train_rmse = rmse(model.predict(train_inputs), train_targets)\n",
        "    val_rmse = rmse(model.predict(val_inputs), val_targets)\n",
        "    return (train_rmse, val_rmse)\n",
        "\n",
        "def test_param_and_plot(ModelClass, param_name, param_values, **other_params):\n",
        "    train_errors, val_errors = [], []\n",
        "    for value in param_values:\n",
        "      params = dict(other_params)\n",
        "      params[param_name] = value\n",
        "      train_rmse, val_rmse = test_params(ModelClass, **params)\n",
        "      train_errors.append(train_rmse)\n",
        "      val_errors.append(val_rmse)\n",
        "    plt.figure(figsize = (10,6))\n",
        "    plt.title('Overfitting curve:' + param_name)\n",
        "    plt.plot(param_values, train_errors, 'b-o')\n",
        "    plt.plot(param_values, val_errors, 'r-o')\n",
        "    plt.xlabel(param_name)\n",
        "    plt.ylabel('RMSE')\n",
        "    plt.legend(['Training','Validation'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1Vt5dBj_AA-"
      },
      "outputs": [],
      "source": [
        "best_params = {\n",
        "    'random_state': 42,\n",
        "    'n_jobs': -1,\n",
        "    'objective': 'reg:squarederror'\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpbSM32DFf-z"
      },
      "source": [
        "(8.1) Number of Trees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jh5QuyAqFeRE"
      },
      "outputs": [],
      "source": [
        "test_param_and_plot(XGBRegressor, 'n_estimators', [100,200,300,400,500], **best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBSeq1BphU8J"
      },
      "source": [
        "400 estimators has the lowest rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JBMROOQV6Esl"
      },
      "outputs": [],
      "source": [
        "best_params['num_estimators'] = 400"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD3FIGYNOk1B"
      },
      "source": [
        "(8.2) Max Depth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JMGzcueyxWYS"
      },
      "outputs": [],
      "source": [
        " test_param_and_plot(XGBRegressor, 'max_depth', [3,5,6,7,8,9,10,11,12,14,16,20,24,26,30,40], **best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNYmo9_G2kFn"
      },
      "source": [
        "The max depth of 6 gives us the lowest rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aqjlb69aCb8u"
      },
      "outputs": [],
      "source": [
        "best_params['max_depth'] = 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxbT43OVta8r"
      },
      "source": [
        "(8.3) Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8qHLA52Ch5r"
      },
      "outputs": [],
      "source": [
        "test_param_and_plot(XGBRegressor, 'learning_rate', [0.05,0.1,0.2,0.3,0.4,0.6,0.7,0.8,1.0,1.2] ,**best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPk-neGrIjpW"
      },
      "source": [
        "The best learning rate seems to be 0.20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rgnG_yxItVw"
      },
      "outputs": [],
      "source": [
        "best_params['learning_rate'] = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Br9Ox9oyj8pZ"
      },
      "outputs": [],
      "source": [
        "jovian.commit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcJl3f8JIiKh"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}